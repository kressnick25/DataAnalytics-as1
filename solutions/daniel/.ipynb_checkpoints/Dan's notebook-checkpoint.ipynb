{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pydot\n",
    "from io import BytesIO\n",
    "from sklearn.tree import export_graphviz\n",
    "df = pd.read_csv('./HouseholderAtRisk.csv')\n",
    "def analyse_feature_importance(dm_model, feature_names, n_to_display=20):\n",
    "    # grab feature importances from the model\n",
    "    importances = dm_model.feature_importances_\n",
    "    \n",
    "    # sort them out in descending order\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "\n",
    "    # limit to 20 features, you can leave this out to print out everything\n",
    "    indices = indices[:n_to_display]\n",
    "\n",
    "    for i in indices:\n",
    "        print(feature_names[i] + ': ' + str(importances[i]))\n",
    "        \n",
    "def visualize_decision_tree(dm_model, feature_names, save_name):\n",
    "    dotfile = BytesIO()\n",
    "    export_graphviz(dm_model, out_file=dotfile, feature_names=feature_names)\n",
    "    graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "    graph[0].write_png(save_name) # saved in the following file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 1</h2>\n",
    "<h3>1. What is the proportion of householders at risk?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High    30498\n",
      "Low      9501\n",
      "Name: AtRisk, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['AtRisk'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of 39999 observations, we found\n",
    "High Risk : 30498 (76.247%)\n",
    "Low Risk: 9501 (23.753%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.Did you have to fix any data quality problems?</h3>\n",
    "\n",
    "Missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                            0\n",
      "Age                         967\n",
      "WorkClass                   972\n",
      "Weighting                  1292\n",
      "Education                   972\n",
      "NumYearsEducation           972\n",
      "MaritalStatus               972\n",
      "Occupation                  986\n",
      "Relationship                972\n",
      "Race                      39954\n",
      "Gender                      972\n",
      "CapitalLoss                 972\n",
      "CapitalGain                 972\n",
      "CapitalAvg                  972\n",
      "NumWorkingHoursPerWeek      972\n",
      "Sex                         972\n",
      "Country                      30\n",
      "AtRisk                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following attributes had quality problems:\n",
    "<h5>Race</h5>\n",
    "Most values in this attribute were missing.\n",
    "The fix was to drop this column.\n",
    "<h5>Age</h5>\n",
    "There were a few values less than 1 and there were 968 missing values.\n",
    "These values were imputed with the mean value of 38.66.\n",
    "<h5>WorkClass</h5>\n",
    "The values were prepended with a space. The space was removed .\n",
    "There were 2240 records with invalid value of \"?\". There were 972 missing values. These values were imputed with the mode \"Private\".\n",
    "<h5>NumYearsEducation</h5>\n",
    "There were 972 missing values. These values were replaced with the mean value of 10.\n",
    "<h5>MaritalStatus</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "There were 972 missing values. These were replaced with the mode \"Married-civ-spouse\".\n",
    "<h5>Occupation</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "There were 2246 records with invalid value of \"?\" and there were 986 missing values. These values were imputed with the mode \"Prof-specialty\".\n",
    "<h5>Relationship</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "The 972 missing values were imputed with ‘Husband’ which is the mode. \n",
    "<h5>CapitalLoss</h5>\n",
    "The 972 missing values were imputed with the mode of 0. Considering the values being skewed to the far left, it makes sense to impute 0 to the missing values.\n",
    "<h5>CapitalGain</h5>\n",
    "The 972 missing values were imputed with the mode of 0.\n",
    "<h5>CapitalAvg</h5>\n",
    "The 972 missing values were imputed with the mode of 0.\n",
    "<h5>NumWorkingHoursPerWeek</h5>\n",
    "There were 972 missing values. These values were imputed with the mean value of 40.\n",
    "<h5>Sex</h5>\n",
    "There were 972 missing values. These values were imputed with the mode of 0.\n",
    "<h5>Country</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "<p>699 values were ‘?’ - These were imputed with the mode‘United-States’.</p>\n",
    "<p>30 missing values were imputed with ‘United-States’</p>\n",
    "<p>917 values were ‘USA’ - These were changed to ‘United-States’</p>\n",
    "<p>9 values were ‘US’ - These were changed to ‘United-States’</p>\n",
    "<p>20 values were ‘Hong’ - These were changed to ‘Hong Kong’</p>\n",
    "<p>97 values were South - These were imputed with 'United-States'</p>\n",
    "\n",
    "<h3>Data types</h3>\n",
    "<h5>Age</h5>\n",
    "The data type was converted from float to int.\n",
    "<h5>Sex</h5>\n",
    "The data type was converted from float to binary.\n",
    "<h5>NumYearsEducation</h5>\n",
    "The data type was converted from float to int.\n",
    "<h5>Weighting</h5>\n",
    "The data type was converted from float to int.\n",
    "<h5>AtRisk</h5>\n",
    "There are only two possible values 'High' or 'Low'. This can be formatted as binary variable.\n",
    "\n",
    "<h3>One-Hot Encoding</h3>\n",
    "The following categorical variables needs to be converted to numerical variables\n",
    "<h5>Country</h5>\n",
    "<h5>MaritalStatus</h5>\n",
    "<h5>Occupation</h5>\n",
    "<h5>Relationship</h5>\n",
    "<h5>Country</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Irrelevant and redundant variables</h3>\n",
    "\n",
    "<h5>ID</h5>\n",
    "This attribute is a unique identifier and does not provide useful information for predicting the target variable.\n",
    "<h5>Gender</h5>\n",
    "This attribute is identical to Sex attribute but with different name. Sex attribute was chosen over this because when there are only two possible values it is better to transform it to binary variable. \n",
    "<h5>Education</h5>\n",
    "Education attribute and NumYearsEducation is essentially a one-to-one mapping except that Education attribute is ordinal but NumYearsEducation is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID, Weighting, Race, Gender, Education\n",
    "df.drop(['ID', 'Race', 'Gender', 'Education'], axis=1, inplace=True)\n",
    "\n",
    "### Age Column\n",
    "# Age less than 1 is invalid\n",
    "# Impute the invalid values and missing values with mean\n",
    "# because ...\n",
    "mask = df['Age'] < 1\n",
    "df.loc[mask, 'Age'] = np.nan\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "### WorkClass column\n",
    "# Remove spaces\n",
    "for uniq in df['WorkClass'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['WorkClass'] == uniq\n",
    "        df.loc[mask, 'WorkClass'] = uniq[1:]\n",
    "\n",
    "mask = df['WorkClass'] == '?'\n",
    "df.loc[mask, 'WorkClass'] = np.nan\n",
    "df['WorkClass'].fillna('Private', inplace=True)\n",
    "\n",
    "### Weighting column\n",
    "df['Weighting'].fillna(df['Weighting'].mean(), inplace=True)\n",
    "\n",
    "### NumYearsEducation column\n",
    "df['NumYearsEducation'].fillna(df['NumYearsEducation'].mean(), inplace=True)\n",
    "\n",
    "### MaritalStatus column\n",
    "# Remove spaces\n",
    "for uniq in df['MaritalStatus'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['MaritalStatus'] == uniq\n",
    "        df.loc[mask, 'MaritalStatus'] = uniq[1:]\n",
    "\n",
    "df['MaritalStatus'].fillna('Married-civ-spouse', inplace=True)\n",
    "\n",
    "### Occupation column\n",
    "for uniq in df['Occupation'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['Occupation'] == uniq\n",
    "        df.loc[mask, 'Occupation'] = uniq[1:]\n",
    "\n",
    "mask = df['Occupation'] == '?'\n",
    "df.loc[mask, 'Occupation'] = np.nan\n",
    "df['Occupation'].fillna('Prof-specialty', inplace=True)\n",
    "\n",
    "### Relationship column\n",
    "# Remove spaces\n",
    "for uniq in df['Relationship'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['Relationship'] == uniq\n",
    "        df.loc[mask, 'Relationship'] = uniq[1:]\n",
    "\n",
    "df['Relationship'].fillna('Husband', inplace=True)\n",
    "\n",
    "### CapitalLoss column\n",
    "# Impute missing values with 0 which is the median\n",
    "# because the data has great outliers (Skewed to left)\n",
    "df['CapitalLoss'].fillna(0, inplace=True)\n",
    "\n",
    "### CapitalGain column\n",
    "# Impute missing values with 0\n",
    "df['CapitalGain'].fillna(0, inplace=True)\n",
    "\n",
    "### CapitalAvg column\n",
    "# Impute with 0\n",
    "df['CapitalAvg'].fillna(0, inplace=True)\n",
    "\n",
    "### NumWorkingHoursPerWeek column\n",
    "# Impute with mean of 40\n",
    "df['NumWorkingHoursPerWeek'].fillna(df['NumWorkingHoursPerWeek'].mean(), inplace=True)\n",
    "\n",
    "### Sex column\n",
    "# Impute with 0 which is the mode\n",
    "df['Sex'].fillna(0, inplace=True)\n",
    "\n",
    "### Country column\n",
    "# Remove spaces \n",
    "for uniq in df['Country'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['Country'] == uniq\n",
    "        df.loc[mask, 'Country'] = uniq[1:]\n",
    "\n",
    "mask = df['Country'] == '?'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "mask = df['Country'] == 'USA'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "mask = df['Country'] == 'US'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "mask = df['Country'] == 'Hong'\n",
    "df.loc[mask, 'Country'] = 'Hong Kong'\n",
    "mask = df['Country'] == 'South'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "df['Country'].fillna('United-States', inplace=True)\n",
    "\n",
    "### Data types\n",
    "# format Sex to binary\n",
    "data_type_map = {1.0: 1, 0.0: 0}\n",
    "df['Sex'] = df['Sex'].map(data_type_map)\n",
    "# format Age to int\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "# # format NumYearsEducation to int\n",
    "df['NumYearsEducation'] = df['NumYearsEducation'].astype(int)\n",
    "# format Weighting to int\n",
    "df['Weighting'] = df['Weighting'].astype(int)\n",
    "# # format AtRisk to binary\n",
    "data_type_map = {'High': 1, 'Low': 0}\n",
    "df['AtRisk'] = df['AtRisk'].map(data_type_map)\n",
    "\n",
    "\n",
    "### One-Hot Encoding\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. What distribution scheme did you use? What data partitioning allocation did you set?</h3>\n",
    "I used 70/30 split (Test dataset is 30%) with stratified sampling. I used stratified sampling because our dataset is skewed (76% of instances are high risk). Using random sampling can produce an inaccurate or overfitting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "y = df['AtRisk']\n",
    "x = df.drop(['AtRisk'], axis=1)\n",
    "\n",
    "rs = 20\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "x_mat = x.as_matrix()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 2. Decision Trees</h2>\n",
    "<h3>1. Build a decision tree using the default setting. Examine the tree results and answer the followings</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=20,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=rs)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=20,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a. What is classification accuracy on training and test datasets?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy on training dataset: ', 0.9942855101967928)\n",
      "('Accuracy on test dataset: ', 0.8121666666666667)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training dataset: \", model.score(x_train, y_train))\n",
    "print(\"Accuracy on test dataset: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training Dataset</b>: 99.42% accuracy<br/>\n",
    "<b>Test Dataset</b>: 81.21% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>b. Which variable is used for the first split? What are the variables used for the second split?</h5>\n",
    "The graph image wasn't visible..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>c. What are the 5 important variables in building the tree?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaritalStatus_Married-civ-spouse: 0.19643569062546867\n",
      "Weighting: 0.18514243213032736\n",
      "NumYearsEducation: 0.12266823377842039\n",
      "Age: 0.12095449603378713\n",
      "CapitalGain: 0.08649375604168594\n"
     ]
    }
   ],
   "source": [
    "analyse_feature_importance(model, x.columns, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 important variable are:<br/>\n",
    "MaritalStatus_Married-civ-spouse: 0.19643569062546867<br/>\n",
    "Weighting: 0.18514243213032736<br/>\n",
    "NumYearsEducation: 0.12266823377842039<br/>\n",
    "Age: 0.12095449603378713<br/>\n",
    "CapitalGain: 0.08649375604168594<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_decision_tree(model, x.columns, \"./graph1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>d. Report if you see any evidence of model overfitting</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is 18.21% higher for training dataset. This is an evidence of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Build another decision tree tuned with GridSearchCV</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=20,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4, 5, 6], 'min_samples_leaf': [20, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(2, 7), \n",
    "          'min_samples_leaf': range(20, 60, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a. What is classification accuracy on training and test datasets?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.8554948391013965)\n",
      "('Test accuracy:', 0.8540833333333333)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training Dataset</b>: 85.55% accuracy<br/>\n",
    "<b>Test Dataset</b>: 85.41% accuracy<br/>\n",
    "<h5>b. What are the parameters used? Explain your decision.</h5>\n",
    "The hyperparameters used were:\n",
    "<ul>\n",
    "    <li><b>max_depth</b>: To pre-prune the maximal tree. By limiting the maximum depth, we can limit the size of the tree and therefore overfitting</li>\n",
    "    <li><b>min_samples_leaf</b>: Setting larger value for this parameter has similar effect as setting max_depth. It limits the granularity of the tree and reduce overfitting</li>\n",
    "</ul>\n",
    "<h5>What are the optimal parameters for this decision tree?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters of the cross validation before optimization are:\n",
    "max_depth: 6<br/>\n",
    "min_samples_leaf: 30<br/>\n",
    "To optimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=20,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [4, 5, 6, 7], 'min_samples_leaf': [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(4, 8), \n",
    "          'min_samples_leaf': range(25, 35)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.8589592485445908)\n",
      "('Test accuracy:', 0.8555833333333334)\n",
      "{'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 27}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training Dataset</b>: 85.9% accuracy<br/>\n",
    "<b>Test Dataset</b>: 85.56% accuracy<br/>\n",
    "\n",
    "The optimal parameters are:\n",
    "max_depth: 7<br/>\n",
    "min_samples_leaf: 27<br/>\n",
    "<h5>d. Which variable is used for the first split? What are the \n",
    "variables that are used for the second split?</h5>\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_decision_tree(cv.best_estimator_, x.columns, \"./graph2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./graph2.png\"/>\n",
    "<b>First split</b>: MaritalStatus_Married-civ-spouse<br/>\n",
    "<b>Second split</b>: CapitalGain, NumYearsEducation\n",
    "<h5>e. What are the 5 important variables in building the tree? </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaritalStatus_Married-civ-spouse: 0.4268844001353971\n",
      "NumYearsEducation: 0.22390731862508767\n",
      "CapitalAvg: 0.13072234618972783\n",
      "CapitalGain: 0.10450153204574017\n",
      "CapitalLoss: 0.03311808855743001\n"
     ]
    }
   ],
   "source": [
    "analyse_feature_importance(cv.best_estimator_, x.columns, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 important variables are:<br/>\n",
    "MaritalStatus_Married-civ-spouse: 0.4268844001353971<br/>\n",
    "NumYearsEducation: 0.22390731862508767<br/>\n",
    "CapitalAvg: 0.13072234618972783<br/>\n",
    "CapitalGain: 0.10450153204574017<br/>\n",
    "CapitalLoss: 0.03311808855743001<br/>\n",
    "<h5>f. Report if you see any evidence of model overfitting</h5>\n",
    "The accuracy of the model on the training dataset and test dataset is almost the same. Therefore I can say there's no overfitting.\n",
    "<h3>3. What is the significant difference do you see between these two decision tree \n",
    "models</h3>\n",
    "<h5>Performance Difference</h5>\n",
    "The improvement in the decision tree using grid search cross validation was elimination of overfitting and improvement in accuracy in test dataset by 4.35%.\n",
    "<h5>Changes</h5>\n",
    "- depth\n",
    "- feature importance\n",
    "- purity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
