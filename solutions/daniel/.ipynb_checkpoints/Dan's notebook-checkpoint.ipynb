{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pydot\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "df = pd.read_csv('./HouseholderAtRisk.csv')\n",
    "def analyse_feature_importance(dm_model, feature_names, n_to_display=20):\n",
    "    # grab feature importances from the model\n",
    "    importances = dm_model.feature_importances_\n",
    "    \n",
    "    # sort them out in descending order\n",
    "    indices = np.argsort(importances)\n",
    "    indices = np.flip(indices, axis=0)\n",
    "\n",
    "    # limit to 20 features, you can leave this out to print out everything\n",
    "    indices = indices[:n_to_display]\n",
    "\n",
    "    for i in indices:\n",
    "        print(feature_names[i] + ': ' + str(importances[i]))\n",
    "        \n",
    "def visualize_decision_tree(dm_model, feature_names, save_name):\n",
    "    dotfile = BytesIO()\n",
    "    export_graphviz(dm_model, out_file=dotfile, feature_names=feature_names)\n",
    "    graph = pydot.graph_from_dot_data(dotfile.getvalue())\n",
    "    graph[0].write_png(save_name) # saved in the following file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 1</h2>\n",
    "<h3>1. What is the proportion of householders at risk?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High    30498\n",
      "Low      9501\n",
      "Name: AtRisk, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['AtRisk'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of 39999 observations, we found\n",
    "High Risk : 30498 (76.247%)\n",
    "Low Risk: 9501 (23.753%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.Did you have to fix any data quality problems?</h3>\n",
    "\n",
    "Missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                            0\n",
      "Age                         967\n",
      "WorkClass                   972\n",
      "Weighting                  1292\n",
      "Education                   972\n",
      "NumYearsEducation           972\n",
      "MaritalStatus               972\n",
      "Occupation                  986\n",
      "Relationship                972\n",
      "Race                      39954\n",
      "Gender                      972\n",
      "CapitalLoss                 972\n",
      "CapitalGain                 972\n",
      "CapitalAvg                  972\n",
      "NumWorkingHoursPerWeek      972\n",
      "Sex                         972\n",
      "Country                      30\n",
      "AtRisk                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following attributes had quality problems:\n",
    "<h5>Race</h5>\n",
    "Most values in this attribute were missing.\n",
    "The fix was to drop this column.\n",
    "<h5>Age</h5>\n",
    "There were a few values less than 1 and there were 968 missing values.\n",
    "These values were imputed with the mean value of 38.66.\n",
    "<h5>WorkClass</h5>\n",
    "The values were prepended with a space. The space was removed .\n",
    "There were 2240 records with invalid value of \"?\". There were 972 missing values. These values were imputed with the mode \"Private\".\n",
    "<h5>NumYearsEducation</h5>\n",
    "There were 972 missing values. These values were replaced with the mean value of 10.\n",
    "<h5>MaritalStatus</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "There were 972 missing values. These were replaced with the mode \"Married-civ-spouse\".\n",
    "<h5>Occupation</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "There were 2246 records with invalid value of \"?\" and there were 986 missing values. These values were imputed with the mode \"Prof-specialty\".\n",
    "<h5>Relationship</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "The 972 missing values were imputed with ‘Husband’ which is the mode. \n",
    "<h5>CapitalLoss</h5>\n",
    "The 972 missing values were imputed with the mode of 0. Considering the values being skewed to the far left, it makes sense to impute 0 to the missing values.\n",
    "<h5>CapitalGain</h5>\n",
    "The 972 missing values were imputed with the mode of 0.\n",
    "<h5>CapitalAvg</h5>\n",
    "The 972 missing values were imputed with the mode of 0.\n",
    "<h5>NumWorkingHoursPerWeek</h5>\n",
    "There were 972 missing values. These values were imputed with the mean value of 40.\n",
    "<h5>Sex</h5>\n",
    "There were 972 missing values. These values were imputed with the mode of 0.\n",
    "<h5>Country</h5>\n",
    "The values in this attribute were prepended with a space. The space was removed.\n",
    "\n",
    "<p>699 values were ‘?’ - These were imputed with the mode‘United-States’.</p>\n",
    "<p>30 missing values were imputed with ‘United-States’</p>\n",
    "<p>917 values were ‘USA’ - These were changed to ‘United-States’</p>\n",
    "<p>9 values were ‘US’ - These were changed to ‘United-States’</p>\n",
    "<p>20 values were ‘Hong’ - These were changed to ‘Hong Kong’</p>\n",
    "<p>97 values were South - These were imputed with 'United-States'</p>\n",
    "\n",
    "<h3>Data types</h3>\n",
    "<h5>Age</h5>\n",
    "The data type was converted from float to int.\n",
    "<h5>Sex</h5>\n",
    "The data type was converted from float to binary.\n",
    "<h5>NumYearsEducation</h5>\n",
    "The data type was converted from float to int.\n",
    "<h5>Weighting</h5>\n",
    "The data type was converted from float to int.\n",
    "<h5>AtRisk</h5>\n",
    "There are only two possible values 'High' or 'Low'. This can be formatted as binary variable.\n",
    "\n",
    "<h3>One-Hot Encoding</h3>\n",
    "The following categorical variables needs to be converted to numerical variables\n",
    "<h5>Country</h5>\n",
    "<h5>MaritalStatus</h5>\n",
    "<h5>Occupation</h5>\n",
    "<h5>Relationship</h5>\n",
    "<h5>Country</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Irrelevant and redundant variables</h3>\n",
    "\n",
    "<h5>ID</h5>\n",
    "This attribute is a unique identifier and does not provide useful information for predicting the target variable.\n",
    "<h5>Gender</h5>\n",
    "This attribute is identical to Sex attribute but with different name. Sex attribute was chosen over this because when there are only two possible values it is better to transform it to binary variable. \n",
    "<h5>Education</h5>\n",
    "Education attribute and NumYearsEducation is essentially a one-to-one mapping except that Education attribute is ordinal but NumYearsEducation is numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ID, Weighting, Race, Gender, Education\n",
    "df.drop(['ID', 'Race', 'Gender', 'Education'], axis=1, inplace=True)\n",
    "\n",
    "### Age Column\n",
    "# Age less than 1 is invalid\n",
    "# Impute the invalid values and missing values with mean\n",
    "# because ...\n",
    "mask = df['Age'] < 1\n",
    "df.loc[mask, 'Age'] = np.nan\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "### WorkClass column\n",
    "# Remove spaces\n",
    "for uniq in df['WorkClass'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['WorkClass'] == uniq\n",
    "        df.loc[mask, 'WorkClass'] = uniq[1:]\n",
    "\n",
    "mask = df['WorkClass'] == '?'\n",
    "df.loc[mask, 'WorkClass'] = np.nan\n",
    "df['WorkClass'].fillna('Private', inplace=True)\n",
    "\n",
    "### Weighting column\n",
    "df['Weighting'].fillna(df['Weighting'].mean(), inplace=True)\n",
    "\n",
    "### NumYearsEducation column\n",
    "df['NumYearsEducation'].fillna(df['NumYearsEducation'].mean(), inplace=True)\n",
    "\n",
    "### MaritalStatus column\n",
    "# Remove spaces\n",
    "for uniq in df['MaritalStatus'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['MaritalStatus'] == uniq\n",
    "        df.loc[mask, 'MaritalStatus'] = uniq[1:]\n",
    "\n",
    "df['MaritalStatus'].fillna('Married-civ-spouse', inplace=True)\n",
    "\n",
    "### Occupation column\n",
    "for uniq in df['Occupation'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['Occupation'] == uniq\n",
    "        df.loc[mask, 'Occupation'] = uniq[1:]\n",
    "\n",
    "mask = df['Occupation'] == '?'\n",
    "df.loc[mask, 'Occupation'] = np.nan\n",
    "df['Occupation'].fillna('Prof-specialty', inplace=True)\n",
    "\n",
    "### Relationship column\n",
    "# Remove spaces\n",
    "for uniq in df['Relationship'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['Relationship'] == uniq\n",
    "        df.loc[mask, 'Relationship'] = uniq[1:]\n",
    "\n",
    "df['Relationship'].fillna('Husband', inplace=True)\n",
    "\n",
    "### CapitalLoss column\n",
    "# Impute missing values with 0 which is the median\n",
    "# because the data has great outliers (Skewed to left)\n",
    "df['CapitalLoss'].fillna(0, inplace=True)\n",
    "\n",
    "### CapitalGain column\n",
    "# Impute missing values with 0\n",
    "df['CapitalGain'].fillna(0, inplace=True)\n",
    "\n",
    "### CapitalAvg column\n",
    "# Impute with 0\n",
    "df['CapitalAvg'].fillna(0, inplace=True)\n",
    "\n",
    "### NumWorkingHoursPerWeek column\n",
    "# Impute with mean of 40\n",
    "df['NumWorkingHoursPerWeek'].fillna(df['NumWorkingHoursPerWeek'].mean(), inplace=True)\n",
    "\n",
    "### Sex column\n",
    "# Impute with 0 which is the mode\n",
    "df['Sex'].fillna(0, inplace=True)\n",
    "\n",
    "### Country column\n",
    "# Remove spaces \n",
    "for uniq in df['Country'].unique():\n",
    "    if isinstance(uniq, str):\n",
    "        mask = df['Country'] == uniq\n",
    "        df.loc[mask, 'Country'] = uniq[1:]\n",
    "\n",
    "mask = df['Country'] == '?'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "mask = df['Country'] == 'USA'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "mask = df['Country'] == 'US'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "mask = df['Country'] == 'Hong'\n",
    "df.loc[mask, 'Country'] = 'Hong Kong'\n",
    "mask = df['Country'] == 'South'\n",
    "df.loc[mask, 'Country'] = 'United-States'\n",
    "df['Country'].fillna('United-States', inplace=True)\n",
    "\n",
    "### Data types\n",
    "# format Sex to binary\n",
    "data_type_map = {1.0: 1, 0.0: 0}\n",
    "df['Sex'] = df['Sex'].map(data_type_map)\n",
    "# format Age to int\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "# # format NumYearsEducation to int\n",
    "df['NumYearsEducation'] = df['NumYearsEducation'].astype(int)\n",
    "# format Weighting to int\n",
    "df['Weighting'] = df['Weighting'].astype(int)\n",
    "# # format AtRisk to binary\n",
    "data_type_map = {'High': 1, 'Low': 0}\n",
    "df['AtRisk'] = df['AtRisk'].map(data_type_map)\n",
    "\n",
    "\n",
    "### One-Hot Encoding\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. What distribution scheme did you use? What data partitioning allocation did you set?</h3>\n",
    "I used 70/30 split (Test dataset is 30%) with stratified sampling. I used stratified sampling because our dataset is skewed (76% of instances are high risk). Using random sampling can produce an inaccurate or overfitting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "y = df['AtRisk']\n",
    "x = df.drop(['AtRisk'], axis=1)\n",
    "\n",
    "rs = 20\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "x_mat = x.as_matrix()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_mat, y, test_size=0.3, stratify=y, random_state=rs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 2. Decision Trees</h2>\n",
    "<h3>1. Build a decision tree using the default setting. Examine the tree results and answer the followings</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=20,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=rs)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=20,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a. What is classification accuracy on training and test datasets?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy on training dataset: ', 0.9942855101967928)\n",
      "('Accuracy on test dataset: ', 0.8121666666666667)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training dataset: \", model.score(x_train, y_train))\n",
    "print(\"Accuracy on test dataset: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training Dataset</b>: 99.42% accuracy<br/>\n",
    "<b>Test Dataset</b>: 81.21% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>b. Which variable is used for the first split? What are the variables used for the second split?</h5>\n",
    "The graph image wasn't visible..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>c. What are the 5 important variables in building the tree?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaritalStatus_Married-civ-spouse: 0.19643569062546867\n",
      "Weighting: 0.18514243213032736\n",
      "NumYearsEducation: 0.12266823377842039\n",
      "Age: 0.12095449603378713\n",
      "CapitalGain: 0.08649375604168594\n"
     ]
    }
   ],
   "source": [
    "analyse_feature_importance(model, x.columns, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 important variable are:<br/>\n",
    "MaritalStatus_Married-civ-spouse: 0.19643569062546867<br/>\n",
    "Weighting: 0.18514243213032736<br/>\n",
    "NumYearsEducation: 0.12266823377842039<br/>\n",
    "Age: 0.12095449603378713<br/>\n",
    "CapitalGain: 0.08649375604168594<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_decision_tree(model, x.columns, \"./graph1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>d. Report if you see any evidence of model overfitting</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is 18.21% higher for training dataset. This is an evidence of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Build another decision tree tuned with GridSearchCV</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a073f9d57c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(2, 7), \n",
    "          'min_samples_leaf': range(20, 60, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a. What is classification accuracy on training and test datasets?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.8554948391013965)\n",
      "('Test accuracy:', 0.8540833333333333)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training Dataset</b>: 85.55% accuracy<br/>\n",
    "<b>Test Dataset</b>: 85.41% accuracy<br/>\n",
    "<h5>b. What are the parameters used? Explain your decision.</h5>\n",
    "The hyperparameters used were:\n",
    "<ul>\n",
    "    <li><b>max_depth</b>: To pre-prune the maximal tree. By limiting the maximum depth, we can limit the size of the tree and therefore overfitting</li>\n",
    "    <li><b>min_samples_leaf</b>: Setting larger value for this parameter has similar effect as setting max_depth. It limits the granularity of the tree and reduce overfitting</li>\n",
    "</ul>\n",
    "<h5>What are the optimal parameters for this decision tree?</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters of the cross validation before optimization are:\n",
    "max_depth: 6<br/>\n",
    "min_samples_leaf: 30<br/>\n",
    "To optimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=20,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [4, 5, 6, 7], 'min_samples_leaf': [25, 26, 27, 28, 29, 30, 31, 32, 33, 34]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(4, 8), \n",
    "          'min_samples_leaf': range(25, 35)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.8589592485445908)\n",
      "('Test accuracy:', 0.8555833333333334)\n",
      "{'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 27}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", cv.score(x_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(x_test, y_test))\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training Dataset</b>: 85.9% accuracy<br/>\n",
    "<b>Test Dataset</b>: 85.56% accuracy<br/>\n",
    "\n",
    "The optimal parameters are:\n",
    "max_depth: 7<br/>\n",
    "min_samples_leaf: 27<br/>\n",
    "<h5>d. Which variable is used for the first split? What are the \n",
    "variables that are used for the second split?</h5>\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_decision_tree(cv.best_estimator_, x.columns, \"./graph2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./graph2.png\"/>\n",
    "<b>First split</b>: MaritalStatus_Married-civ-spouse<br/>\n",
    "<b>Second split</b>: CapitalGain, NumYearsEducation\n",
    "<h5>e. What are the 5 important variables in building the tree? </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaritalStatus_Married-civ-spouse: 0.4268844001353971\n",
      "NumYearsEducation: 0.22390731862508767\n",
      "CapitalAvg: 0.13072234618972783\n",
      "CapitalGain: 0.10450153204574017\n",
      "CapitalLoss: 0.03311808855743001\n"
     ]
    }
   ],
   "source": [
    "analyse_feature_importance(cv.best_estimator_, x.columns, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 5 important variables are:<br/>\n",
    "MaritalStatus_Married-civ-spouse: 0.4268844001353971<br/>\n",
    "NumYearsEducation: 0.22390731862508767<br/>\n",
    "CapitalAvg: 0.13072234618972783<br/>\n",
    "CapitalGain: 0.10450153204574017<br/>\n",
    "CapitalLoss: 0.03311808855743001<br/>\n",
    "<h5>f. Report if you see any evidence of model overfitting</h5>\n",
    "The accuracy of the model on the training dataset and test dataset is almost the same. Therefore I can say there's no overfitting.\n",
    "<h3>3. What is the significant difference do you see between these two decision tree \n",
    "models</h3>\n",
    "<h5>Performance Difference</h5>\n",
    "The improvement in the decision tree using grid search cross validation was elimination of overfitting and improvement in accuracy in test dataset by 4.35%.\n",
    "This improvement is due to cross validation and tree pruning to reduce overfitting on training data and making the model more generalized. \n",
    "<h5>Other Changes</h5>\n",
    "<p>- depth:<br/>\n",
    "The depth of the latter model was 7 and the depth of the previous model was ...\n",
    "</p>\n",
    "<p>- feature importance:<br/>\n",
    "Both models have MaritalStatus_Married-civ-spouse as their most important variable. However the variable's importance was 0.1964 in the previous model and 0.4269 in the latter model. This means the latter model's splitting is much better than the previous model. This may be the result of cross validation and tree pruning.\n",
    "</p>\n",
    "<h3>4.From the better model, can you identify which householders to target for providing loan? Can you provide some descriptive summary of those householders?</h3>\n",
    "Based on the feature importance and the value split in each node, the following criteria provide the purest split. \n",
    "<p>The householder should meet the following criteria:<br/>\n",
    "MaritalStatus_Married-civ-spouse >= 0.5<br/>\n",
    "NumYearsEducation > 11.5<br/>\n",
    "CapitalAvg > 2547.75<br/>\n",
    "WorkClass_Self-emp-not-inc <= 0.5\n",
    "</p>\n",
    "<br/>\n",
    "\n",
    "This means the householder must be married, have a very high level of education (more than 11.5 years),have a significant amount of investment (CapitalAvg of more than 2547.75), and not self employed to have a very low chance of being at risk.\n",
    "<h2>Task 3</h2>\n",
    "<h3>1. Describe why you will have to do additional preparation for variables to be used in regression modelling. Apply transformation methods to the variables that need.</h3>\n",
    "The transformations that needs to be performed on the dataset are standardisation and logarithmic transformation. Our dataset requires standardisation because the input variables are of different scales. For example, Age attribute ranges from 17 to 90 whereas CapitalGain attribute ranges from 0 to 99999. The differences in the scale can affect model performance. Some of the attributes in our dataset requires logarithmic transformation. Logarithmic transformation is used to modify the distribution of input values. Skewed attribute with extreme values can negatively affect model performance.\n",
    "\n",
    "<img src=\"./skew.png\"/>\n",
    "The Age, Weighting, CapitalGain and CapitalAvg attributes have different level of skewedness with Age being the least skewed.\n",
    "<h5>Logarithmic Transformation</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = ['Age', 'Weighting','CapitalGain', 'CapitalAvg']\n",
    "df_log = df.copy()\n",
    "for col in columns_to_transform:\n",
    "    df_log[col] = df_log[col].apply(lambda x: x+1)\n",
    "    df_log[col] = df_log[col].apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After logarithmic transformation, the attributes' value distribution looks like:<br/>\n",
    "<img src=\"./skew2.png\"/>\n",
    "\n",
    "<h5>Partitioning data again using the df_log.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = df_log['AtRisk']\n",
    "x_log = df_log.drop(['AtRisk'], axis=1)\n",
    "x_mat_log = x_log.as_matrix()\n",
    "x_train_log, x_test_log, y_train_log, y_test_log = train_test_split(x_mat_log, y_log, test_size=0.3, stratify=y_log, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Standardisation</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_log_scaled = scaler.fit_transform(x_train_log, y_train_log)\n",
    "x_test_log_scaled = scaler.transform(x_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Build a regression model using the default regression method with all inputs. Once you have completed it, build another model ad tune it using GridSearchCV.</h3>\n",
    "<h5>Building Logistic Regression model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.843315832708311)\n",
      "('Test accuracy:', 0.8444166666666667)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=rs)\n",
    "model.fit(x_train_log_scaled, y_train_log)\n",
    "print(\n",
    "    \"Train accuracy:\", \n",
    "    model.score(x_train_log_scaled, y_train_log)\n",
    ")\n",
    "print(\n",
    "    \"Test accuracy:\", \n",
    "    model.score(x_test_log_scaled, y_test_log)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Building model using GridSearchCV</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.843280117147041)\n",
      "('Test accuracy:', 0.8445833333333334)\n"
     ]
    }
   ],
   "source": [
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "regression_cv = GridSearchCV(\n",
    "    param_grid=params, \n",
    "    estimator=LogisticRegression(random_state=rs),\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "regression_cv.fit(x_train_log_scaled, y_train_log)\n",
    "print(\n",
    "    \"Train accuracy:\", \n",
    "    regression_cv.score(x_train_log_scaled, y_train_log)\n",
    ")\n",
    "print(\n",
    "    \"Test accuracy:\", \n",
    "    regression_cv.score(x_test_log_scaled, y_test_log)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(regression_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Feature importance</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NumYearsEducation', ':', -0.7713223988970697)\n",
      "('CapitalGain', ':', -0.7092790273413643)\n",
      "('MaritalStatus_Married-civ-spouse', ':', -0.6824070765694628)\n",
      "('MaritalStatus_Never-married', ':', 0.47490755998987544)\n",
      "('CapitalLoss', ':', -0.42201472689663533)\n",
      "('Age', ':', -0.4073679352192773)\n",
      "('NumWorkingHoursPerWeek', ':', -0.3796473502079174)\n",
      "('Sex', ':', 0.3349421856709397)\n",
      "('CapitalAvg', ':', 0.27588106707331594)\n",
      "('Relationship_Wife', ':', -0.2451533201990667)\n",
      "('MaritalStatus_Divorced', ':', 0.24396799458915286)\n",
      "('Occupation_Other-service', ':', 0.24009205863436325)\n",
      "('Relationship_Own-child', ':', 0.23522230733515337)\n",
      "('Occupation_Exec-managerial', ':', -0.2256644917590636)\n",
      "('Occupation_Farming-fishing', ':', 0.14719398689140684)\n",
      "('Relationship_Not-in-family', ':', -0.14463151840285432)\n",
      "('Occupation_Handlers-cleaners', ':', 0.13614919951645157)\n",
      "('Country_Guatemala', ':', 0.1327825977359868)\n",
      "('Relationship_Other-relative', ':', 0.1142294800296075)\n",
      "('Occupation_Priv-house-serv', ':', 0.11074903606033357)\n"
     ]
    }
   ],
   "source": [
    "feature_names = x_log.columns\n",
    "coef = regression_cv.best_estimator_.coef_[0]\n",
    "\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a. Report which variables are included in the regression model</h5>\n",
    "All 83 input variables are included in the model.\n",
    "<h5>b. Report the top-5 important variables in the model</h5>\n",
    "<p>\n",
    "NumYearsEducation: -0.7713223988970697<br/>\n",
    "CapitalGain: -0.7092790273413643<br/>\n",
    "MaritalStatus_Married-civ-spouse: -0.6824070765694628<br/>\n",
    "MaritalStatus_Never-married: 0.47490755998987544<br/>\n",
    "CapitalLoss: -0.42201472689663533\n",
    "</p>\n",
    "<h5>c. Report any sign of overfitting</h5>\n",
    "The training accuracy and test accuracy of the model was almost identical. This means there's very little overfitting.\n",
    "<h5>d. What are the parameters used? Explain your decision. What are the optimal parameters? Which regression function is being used?</h5>\n",
    "The parameter used was the regularisation strength which is represented as C. The range of values used for this parameter was [pow(10, x) for x in range(-6, 4)]. The regularisation strength was used to reduce overfitting.\n",
    "<p>\n",
    "The optimal parameter is C: 0.1\n",
    "</p>\n",
    "\n",
    "<h5>e. What is classification accuracy on training and test datasets?</h5>\n",
    "<p>\n",
    "The accuracy of model built using the default regression method was a follows:<br/>\n",
    "Train accuracy: 0.843315832708311<br/>\n",
    "Test accuracy: 0.8444166666666667\n",
    "</p>\n",
    "<p>\n",
    "The accuracy of model built using GridSearchCV was a follows:<br/>\n",
    "Train accuracy: 0.843280117147041<br/>\n",
    "Test accuracy: 0.8445833333333334\n",
    "</p>\n",
    "<h3>3. Build another regression model using the subset of inputs selected either by RFE or the selection by model method</h3>\n",
    "<h5>Using recursive feature elimination</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Original feature set', 83)\n",
      "('Number of features after elimination', 44)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfe = RFECV(\n",
    "    estimator = LogisticRegression(random_state=rs), \n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rfe.fit(x_train_log_scaled, y_train_log) # run the RFECV\n",
    "\n",
    "# comparing how many variables before and after\n",
    "print(\"Original feature set\", x_train_log_scaled.shape[1])\n",
    "print(\"Number of features after elimination\", rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.843315832708311)\n",
      "('Test accuracy:', 0.8455)\n"
     ]
    }
   ],
   "source": [
    "x_train_log_scaled_sel = rfe.transform(x_train_log_scaled)\n",
    "x_test_log_scaled_sel = rfe.transform(x_test_log_scaled)\n",
    "\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "regression_cv = GridSearchCV(\n",
    "    param_grid=params, \n",
    "    estimator=LogisticRegression(random_state=rs),\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "regression_cv.fit(x_train_log_scaled_sel, y_train_log)\n",
    "print(\n",
    "    \"Train accuracy:\", \n",
    "    regression_cv.score(x_train_log_scaled_sel, y_train_log)\n",
    ")\n",
    "print(\n",
    "    \"Test accuracy:\", \n",
    "    regression_cv.score(x_test_log_scaled_sel, y_test_log)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NumYearsEducation', ':', -0.7084501674400273)\n",
      "('WorkClass_State-gov', ':', -0.4605340082385802)\n",
      "('Age', ':', -0.36480469670520127)\n",
      "('MaritalStatus_Divorced', ':', 0.35113976967417915)\n",
      "('NumWorkingHoursPerWeek', ':', -0.3475917918739649)\n",
      "('CapitalGain', ':', -0.3289549347843966)\n",
      "('Occupation_Protective-serv', ':', -0.3129291628978554)\n",
      "('Sex', ':', 0.28529889029523775)\n",
      "('Occupation_Craft-repair', ':', 0.25196224284596136)\n",
      "('Occupation_Machine-op-inspct', ':', -0.22020808442387893)\n",
      "('WorkClass_Self-emp-not-inc', ':', 0.17861811128784116)\n",
      "('CapitalLoss', ':', -0.1773617505303366)\n",
      "('MaritalStatus_Widowed', ':', 0.1671117388758829)\n",
      "('Occupation_Prof-specialty', ':', 0.16169442039327117)\n",
      "('MaritalStatus_Separated', ':', -0.16136619051419826)\n",
      "('Occupation_Adm-clerical', ':', 0.15749077787279187)\n",
      "('CapitalAvg', ':', -0.14697160470052406)\n",
      "('Occupation_Armed-Forces', ':', 0.1104928136232001)\n",
      "('WorkClass_Federal-gov', ':', -0.10771992718011499)\n",
      "('Occupation_Other-service', ':', -0.08570893153829656)\n"
     ]
    }
   ],
   "source": [
    "feature_names = x_log.columns\n",
    "coef = regression_cv.best_estimator_.coef_[0]\n",
    "\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Feature selection using another model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 30}\n"
     ]
    }
   ],
   "source": [
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(2, 7), \n",
    "          'min_samples_leaf': range(20, 60, 10)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(random_state=rs), cv=10)\n",
    "cv.fit(x_train_log_scaled, y_train_log)\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27999, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "selectmodel = SelectFromModel(cv.best_estimator_, prefit=True)\n",
    "x_train_log_scaled_sel = selectmodel.transform(x_train_log_scaled)\n",
    "x_test_log_scaled_sel = selectmodel.transform(x_test_log_scaled)\n",
    "\n",
    "print(x_train_log_scaled_sel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train accuracy:', 0.8362084360155719)\n",
      "('Test accuracy:', 0.8401666666666666)\n",
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "regression_cv = GridSearchCV(\n",
    "    param_grid=params, \n",
    "    estimator=LogisticRegression(random_state=rs), \n",
    "    cv=10, n_jobs=-1)\n",
    "regression_cv.fit(x_train_log_scaled_sel, y_train_log)\n",
    "\n",
    "print(\"Train accuracy:\", regression_cv.score(x_train_log_scaled_sel, y_train_log))\n",
    "print(\"Test accuracy:\", regression_cv.score(x_test_log_scaled_sel, y_test_log))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(regression_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NumWorkingHoursPerWeek', ':', -1.1881493943066028)\n",
      "('CapitalLoss', ':', -0.9807762139353696)\n",
      "('Weighting', ':', -0.8728766612594224)\n",
      "('NumYearsEducation', ':', -0.5940253766158401)\n",
      "('CapitalGain', ':', 0.5793449367701083)\n",
      "('Age', ':', -0.4377330832156579)\n",
      "('CapitalAvg', ':', -0.35342412203272106)\n",
      "('Sex', ':', -0.22395583109399927)\n"
     ]
    }
   ],
   "source": [
    "feature_names = x_log.columns\n",
    "coef = regression_cv.best_estimator_.coef_[0]\n",
    "\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>a. Report which variables are included in the regression model</h5>\n",
    "<p>\n",
    "Using RFE, <br/>\n",
    "Original feature set: 83 <br/>\n",
    "Number of features after elimination: 44\n",
    "</p>\n",
    "<p>\n",
    "Using feature selection using another model<br/>\n",
    "Number of features after elimination: 8\n",
    "</p>\n",
    "<h5>b. Report the top-5 important variables in the model</h5>\n",
    "Using RFE,<br/>\n",
    "NumYearsEducation: -0.7084501674400273<br/>\n",
    "WorkClass_State-gov: -0.4605340082385802<br/>\n",
    "Age: -0.36480469670520127<br/>\n",
    "MaritalStatus_Divorced: 0.35113976967417915<br/>\n",
    "NumWorkingHoursPerWeek: -0.3475917918739649<br/><br/>\n",
    "\n",
    "Using feature selection using another model<br/>\n",
    "NumWorkingHoursPerWeek: -1.1881493943066028<br/>\n",
    "CapitalLoss: -0.9807762139353696<br/>\n",
    "Weighting: -0.8728766612594224<br/>\n",
    "NumYearsEducation: -0.5940253766158401<br/>\n",
    "CapitalGain: 0.5793449367701083\n",
    "<h5>a. Report any sign of overfitting</h5>\n",
    "The training accuracy and test accuracy of the model was almost identical. This means there's very little overfitting.\n",
    "<h5>a. What is the classification accuracy on training and test datasets?</h5>\n",
    "<p>\n",
    "Using RFE, <br/>\n",
    "Train accuracy: 0.843315832708311<br/>\n",
    "Test accuracy: 0.8455\n",
    "</p>\n",
    "<p>\n",
    "Using feature selection using another model<br/>\n",
    "Train accuracy: 0.8362084360155719<br/>\n",
    "Test accuracy: 0.8401666666666666\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Using the comparison statistics, which of the regression models appears to be better? Is there any difference between the two models? Explain why those changes may have happened.</h3>\n",
    "<p>\n",
    "There's a very little difference between the two models in terms of the performance. The test accuracy of the model that includes all variables was 0.8445833333333334 and the performance of the model using RFE was 0.8455.\n",
    "</p>\n",
    "<p>\n",
    "Another difference was the feature importance.<br/>\n",
    "The previous model's feature importance was: <br/>\n",
    "NumYearsEducation: -0.7713223988970697<br/>\n",
    "CapitalGain: -0.7092790273413643<br/>\n",
    "MaritalStatus_Married-civ-spouse: -0.6824070765694628<br/>\n",
    "MaritalStatus_Never-married: 0.47490755998987544<br/>\n",
    "CapitalLoss: -0.42201472689663533 <br/><br/>\n",
    "    \n",
    "The model using RFE's feature importance was: <br/>\n",
    "NumYearsEducation: -0.7084501674400273<br/>\n",
    "WorkClass_State-gov: -0.4605340082385802<br/>\n",
    "Age: -0.36480469670520127<br/>\n",
    "MaritalStatus_Divorced: 0.35113976967417915<br/>\n",
    "NumWorkingHoursPerWeek: -0.3475917918739649<br/><br/>\n",
    "\n",
    "Since the model using RFE has reduced the feature set size from 83 to 44, its process is faster than the previous model. Therefore the latter model is better.\n",
    "</p>\n",
    "<h3>From the better model, can you identify which householders to target for providing loan? Can you provide some descriptive summary of those householders?</h3>\n",
    "<p>\n",
    "Based on the feature importance and coefficients the householder: <br/>\n",
    "- Should have high level of education<br/>\n",
    "- Should work at a state government<br/>\n",
    "- Should be aged<br/>\n",
    "- Should not be devorced<br/>\n",
    "- Should have long working hour per week <br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
