{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import dataset\n",
    "df = pd.read_csv('./HouseholderAtRisk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "## Data selection and distribution (4 marks)\n",
    "\n",
    "1. What is the proportion of householders who have high risk?\n",
    "\n",
    "**76.246% of householders have high risk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       High\n",
      "High  30497\n",
      "Low    9501\n",
      "\n",
      " High percentage: 76.24631231561578 %\n"
     ]
    }
   ],
   "source": [
    "print(df['High'].value_counts().to_frame())\n",
    "\n",
    "total = 30497 + 9501\n",
    "print('\\n High percentage:', (30497 / total) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Did you have to fix any data quality problems? Detail them.\n",
    "    Apply the imputation method(s) to the variable(s) that need it. List the variables that needed it. Justify your choise of imputation if needed\n",
    "\n",
    "**Data quality problems**\n",
    "1. Renamed each column with corresponding name\n",
    "2. Drop rows with over 95% NaN values\n",
    "3. Drop rows with more than 8 empty cells\n",
    "\n",
    "\n",
    "**Imputation**\n",
    "1. imputate `occupation` by removal, small percentage to remove and no simple median to apply\n",
    "2. imputate rows in `weighting` by removal, small percentage to remove and no simple median to apply\n",
    "3. imputate rows in `work_class` by applying median value. median value is large majority\n",
    "4. imputate rows in `country_of_origin` by applying median value. median value is large majority\n",
    "\n",
    "**DataTypes**\n",
    "1. map `sex` to __boolean__ type of 0:M and 1:F. changed from __float__\n",
    "2. change `age`, `num_years_education`, `num_working_hours_per_week`, `weighting` from __float__ to __int__\n",
    "\n",
    "**Bin Values**\n",
    "1. Bin `weighting` to remove problem of large range of singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list unique values for each column\n",
    "# check data matches description\n",
    "\n",
    "# for column in df.columns:\n",
    "#     print('\\nColumn name: ' + column )\n",
    "#     print(df[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA QUALITY\n",
    "## 1\n",
    "# rename each column to correct attribute name \n",
    "# according to task description\n",
    "df.rename(columns= {\n",
    "    '1': 'id',\n",
    "    '25': 'age',\n",
    "    ' Private': 'work_class',\n",
    "    '224942': 'weighting',\n",
    "    ' 11th': 'education',\n",
    "    '7': 'num_years_education',\n",
    "    ' Never-married': 'marital_status',\n",
    "    ' Machine-op-inspct': 'occupation',\n",
    "    ' Own-child': 'relationship',\n",
    "    'Unnamed: 9': 'race',\n",
    "    ' Male': 'gender',\n",
    "    '0': 'capital_loss',\n",
    "    '0.1': 'capital_gain',\n",
    "    '0.2': 'capital_avg',\n",
    "    '40': 'num_working_hours_per_week',\n",
    "    '0.3': 'sex',\n",
    "    ' US': 'country_of_origin',\n",
    "    'High': 'at_risk',\n",
    "    \n",
    "}, inplace=True)\n",
    "\n",
    "## 2\n",
    "# Remove near empty columns\n",
    "df.drop(columns=['race', 'capital_loss', 'capital_gain', 'capital_avg'], inplace=True)\n",
    "\n",
    "## 3\n",
    "# Remove rows with nothing but ID\n",
    "df.dropna(thresh=8, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPUTATION\n",
    "## 1\n",
    "# remove rows in 'occupation' with ? value as hard to imputate media\n",
    "df = df[df.occupation != '?']\n",
    "\n",
    "## 2\n",
    "# remove rows in 'weighting' that are NaN as hard to imputate median\n",
    "df.dropna(subset=['weighting'], inplace=True)\n",
    "\n",
    "## 3\n",
    "# imputate rows with ? in 'work_class' as median is easy to determine\n",
    "df['work_class'].replace('?', df['work_class'].mode(), inplace=True)\n",
    "\n",
    "## 4\n",
    "# imputate rows ? in country_of_origin to median of origin\n",
    "df['country_of_origin'].replace('?', df['country_of_origin'].mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA TYPES\n",
    "## 1\n",
    "# change sex to boolean map\n",
    "df['sex'] = df['sex'].map({'M': 0, 'F':1 })\n",
    "\n",
    "## 2\n",
    "# change from float to int\n",
    "df['age'] = df['age'].astype(int);\n",
    "df['num_years_education'] = df['num_years_education'].astype(int)\n",
    "df['num_working_hours_per_week'] = df['num_working_hours_per_week'].astype(int)\n",
    "df['weighting'] = df['weighting'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bin rows\n",
    "df['weighting'] = pd.cut(df['weighting'], 20).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The dataset may include irrelevant and redundant variables. What variables did you include in the analysis and what were their roles and measurement level set? Justify your choice.\n",
    "\n",
    "**1. Large majority of cells are single value**\n",
    "`country_of_origin`, `work_class`\n",
    "\n",
    "**2. Other**\n",
    "`gender`: `sex` column describes same data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['Race'].value_counts(dropna=False), '\\n')\n",
    "# print(df['CapitalLoss'].value_counts(bins = 5), '\\n')\n",
    "# print(df['CapitalGain'].value_counts(bins = 5), '\\n')\n",
    "# print(df['CapitalAvg'].value_counts(bins=5), '\\n')\n",
    "# print(df['CountryOfOrigin'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1\n",
    "df.drop(columns=['country_of_origin', 'work_class'], inplace=True)\n",
    "## 2\n",
    "df.drop(columns=['gender'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What distribution scheme did you use? What “data partitioning allocation” did you set? Explain your selection. (Hint: Take the lead from Week 2 lecture on data distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Predictive Modelling Using Decision Trees (4 marks)\n",
    "1. Build a decision tree using the default setting. Examine the tree results and answer the followings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38706 entries, 0 to 39997\n",
      "Data columns (total 11 columns):\n",
      "id                            38706 non-null int64\n",
      "age                           38706 non-null int32\n",
      "weighting                     29909 non-null float64\n",
      "education                     38706 non-null object\n",
      "num_years_education           38706 non-null int32\n",
      "marital_status                38706 non-null object\n",
      "occupation                    38692 non-null object\n",
      "relationship                  38706 non-null object\n",
      "num_working_hours_per_week    38706 non-null int32\n",
      "sex                           0 non-null float64\n",
      "at_risk                       38706 non-null object\n",
      "dtypes: float64(2), int32(3), int64(1), object(5)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "          id  age  weighting      education  num_years_education  \\\n",
      "0          2   38        NaN        HS-grad                    9   \n",
      "1          3   28        NaN     Assoc-acdm                   12   \n",
      "2          4   44        NaN   Some-college                   10   \n",
      "3          5   18        NaN   Some-college                   10   \n",
      "4          6   34        NaN           10th                    6   \n",
      "5          7   29        NaN        HS-grad                    9   \n",
      "6          8   63        NaN    Prof-school                   15   \n",
      "7          9   24        NaN   Some-college                   10   \n",
      "8         10   55        NaN        7th-8th                    4   \n",
      "9         11   65        NaN        HS-grad                    9   \n",
      "10        12   36        NaN      Bachelors                   13   \n",
      "11        13   26        NaN        HS-grad                    9   \n",
      "12        14   58        NaN        HS-grad                    9   \n",
      "13        15   48        NaN        HS-grad                    9   \n",
      "14        16   43        NaN        Masters                   14   \n",
      "15        17   20        NaN   Some-college                   10   \n",
      "16        18   43        NaN        HS-grad                    9   \n",
      "17        19   37        NaN        HS-grad                    9   \n",
      "18        20   40        NaN      Doctorate                   16   \n",
      "19        21   34        NaN      Bachelors                   13   \n",
      "20        22   34        NaN   Some-college                   10   \n",
      "21        23   72        NaN        7th-8th                    4   \n",
      "22        24   25        NaN      Bachelors                   13   \n",
      "23        25   25        NaN      Bachelors                   13   \n",
      "24        26   45        NaN        HS-grad                    9   \n",
      "25        27   22        NaN        HS-grad                    9   \n",
      "26        28   23        NaN        HS-grad                    9   \n",
      "27        29   54        NaN        HS-grad                    9   \n",
      "28        30   32        NaN   Some-college                   10   \n",
      "29        31   46        NaN   Some-college                   10   \n",
      "...      ...  ...        ...            ...                  ...   \n",
      "39968  39970   25     5345.0     Assoc-acdm                   12   \n",
      "39969  39971   43     5345.0      Bachelors                   13   \n",
      "39970  39972   36     5345.0        HS-grad                    9   \n",
      "39971  39973   41     5345.0        HS-grad                    9   \n",
      "39972  39974   31     5345.0      Bachelors                   13   \n",
      "39973  39975   22     5345.0        HS-grad                    9   \n",
      "39974  39976   36     5345.0      Assoc-voc                   11   \n",
      "39975  39977   42     5345.0           10th                    6   \n",
      "39976  39978   29     5345.0        HS-grad                    9   \n",
      "39977  39979   25     5345.0        HS-grad                    9   \n",
      "39978  39980   23     5345.0      Bachelors                   13   \n",
      "39979  39981   34     5345.0        HS-grad                    9   \n",
      "39980  39982   27     5345.0        HS-grad                    9   \n",
      "39981  39983   32     5345.0      Bachelors                   13   \n",
      "39982  39984   33     5345.0   Some-college                   10   \n",
      "39983  39985   38     5345.0      Bachelors                   13   \n",
      "39984  39986   21     5345.0   Some-college                   10   \n",
      "39985  39987   39     5345.0      Assoc-voc                   11   \n",
      "39986  39988   50     5345.0      Bachelors                   13   \n",
      "39987  39989   32     5345.0   Some-college                   10   \n",
      "39988  39990   40     5345.0        HS-grad                    9   \n",
      "39989  39991   58     5345.0   Some-college                   10   \n",
      "39990  39992   20     5345.0        HS-grad                    9   \n",
      "39991  39993   63     5345.0        HS-grad                    9   \n",
      "39992  39994   56     5345.0      Bachelors                   13   \n",
      "39993  39995   30     5345.0      Bachelors                   13   \n",
      "39994  39996   39     5345.0   Some-college                   10   \n",
      "39995  39997   25     5345.0     Assoc-acdm                   12   \n",
      "39996  39998   33     5345.0        HS-grad                    9   \n",
      "39997  39999   41     5345.0      Bachelors                   13   \n",
      "\n",
      "               marital_status          occupation    relationship  \\\n",
      "0          Married-civ-spouse     Farming-fishing         Husband   \n",
      "1          Married-civ-spouse     Protective-serv         Husband   \n",
      "2          Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "3               Never-married                   ?       Own-child   \n",
      "4               Never-married       Other-service   Not-in-family   \n",
      "5               Never-married                   ?       Unmarried   \n",
      "6          Married-civ-spouse      Prof-specialty         Husband   \n",
      "7               Never-married       Other-service       Unmarried   \n",
      "8          Married-civ-spouse        Craft-repair         Husband   \n",
      "9          Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "10         Married-civ-spouse        Adm-clerical         Husband   \n",
      "11              Never-married        Adm-clerical   Not-in-family   \n",
      "12         Married-civ-spouse                   ?         Husband   \n",
      "13         Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "14         Married-civ-spouse     Exec-managerial         Husband   \n",
      "15              Never-married       Other-service       Own-child   \n",
      "16         Married-civ-spouse        Adm-clerical            Wife   \n",
      "17                    Widowed   Machine-op-inspct       Unmarried   \n",
      "18         Married-civ-spouse      Prof-specialty         Husband   \n",
      "19         Married-civ-spouse        Tech-support         Husband   \n",
      "20              Never-married       Other-service       Own-child   \n",
      "21                   Divorced                   ?   Not-in-family   \n",
      "22              Never-married      Prof-specialty   Not-in-family   \n",
      "23         Married-civ-spouse      Prof-specialty         Husband   \n",
      "24         Married-civ-spouse        Craft-repair         Husband   \n",
      "25              Never-married        Adm-clerical       Own-child   \n",
      "26                  Separated   Machine-op-inspct       Unmarried   \n",
      "27         Married-civ-spouse        Craft-repair         Husband   \n",
      "28              Never-married      Prof-specialty   Not-in-family   \n",
      "29         Married-civ-spouse     Exec-managerial         Husband   \n",
      "...                       ...                 ...             ...   \n",
      "39968                Divorced        Adm-clerical       Unmarried   \n",
      "39969      Married-civ-spouse               Sales       Own-child   \n",
      "39970           Never-married        Craft-repair       Own-child   \n",
      "39971      Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "39972           Never-married      Prof-specialty   Not-in-family   \n",
      "39973           Never-married     Exec-managerial       Own-child   \n",
      "39974      Married-civ-spouse        Craft-repair         Husband   \n",
      "39975      Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "39976      Married-civ-spouse        Craft-repair         Husband   \n",
      "39977           Never-married        Adm-clerical       Unmarried   \n",
      "39978           Never-married     Exec-managerial   Not-in-family   \n",
      "39979               Separated               Sales       Unmarried   \n",
      "39980      Married-civ-spouse        Adm-clerical         Husband   \n",
      "39981      Married-civ-spouse               Sales         Husband   \n",
      "39982   Married-spouse-absent      Prof-specialty   Not-in-family   \n",
      "39983                Divorced     Exec-managerial   Not-in-family   \n",
      "39984           Never-married   Machine-op-inspct       Own-child   \n",
      "39985      Married-civ-spouse        Craft-repair         Husband   \n",
      "39986      Married-civ-spouse     Exec-managerial         Husband   \n",
      "39987           Never-married        Adm-clerical   Not-in-family   \n",
      "39988      Married-civ-spouse     Exec-managerial         Husband   \n",
      "39989      Married-civ-spouse     Exec-managerial         Husband   \n",
      "39990           Never-married        Adm-clerical       Own-child   \n",
      "39991                Divorced                   ?   Not-in-family   \n",
      "39992      Married-civ-spouse        Adm-clerical         Husband   \n",
      "39993      Married-civ-spouse     Protective-serv         Husband   \n",
      "39994                Divorced     Exec-managerial       Unmarried   \n",
      "39995           Never-married      Prof-specialty   Not-in-family   \n",
      "39996      Married-civ-spouse   Machine-op-inspct         Husband   \n",
      "39997           Never-married      Prof-specialty   Not-in-family   \n",
      "\n",
      "       num_working_hours_per_week  sex at_risk  \n",
      "0                              50  NaN    High  \n",
      "1                              40  NaN     Low  \n",
      "2                              40  NaN     Low  \n",
      "3                              30  NaN    High  \n",
      "4                              30  NaN    High  \n",
      "5                              40  NaN    High  \n",
      "6                              32  NaN     Low  \n",
      "7                              40  NaN    High  \n",
      "8                              10  NaN    High  \n",
      "9                              40  NaN     Low  \n",
      "10                             40  NaN    High  \n",
      "11                             39  NaN    High  \n",
      "12                             35  NaN    High  \n",
      "13                             48  NaN     Low  \n",
      "14                             50  NaN     Low  \n",
      "15                             25  NaN    High  \n",
      "16                             30  NaN    High  \n",
      "17                             20  NaN    High  \n",
      "18                             45  NaN     Low  \n",
      "19                             47  NaN     Low  \n",
      "20                             35  NaN    High  \n",
      "21                              6  NaN    High  \n",
      "22                             43  NaN    High  \n",
      "23                             40  NaN    High  \n",
      "24                             90  NaN     Low  \n",
      "25                             20  NaN    High  \n",
      "26                             54  NaN    High  \n",
      "27                             35  NaN    High  \n",
      "28                             60  NaN    High  \n",
      "29                             38  NaN     Low  \n",
      "...                           ...  ...     ...  \n",
      "39968                          40  NaN    High  \n",
      "39969                          40  NaN     Low  \n",
      "39970                          40  NaN    High  \n",
      "39971                          40  NaN    High  \n",
      "39972                          40  NaN    High  \n",
      "39973                          40  NaN    High  \n",
      "39974                          40  NaN    High  \n",
      "39975                          40  NaN    High  \n",
      "39976                          60  NaN    High  \n",
      "39977                          46  NaN    High  \n",
      "39978                          40  NaN    High  \n",
      "39979                          20  NaN    High  \n",
      "39980                          45  NaN    High  \n",
      "39981                          50  NaN     Low  \n",
      "39982                          40  NaN    High  \n",
      "39983                          55  NaN    High  \n",
      "39984                          30  NaN    High  \n",
      "39985                          40  NaN    High  \n",
      "39986                          40  NaN     Low  \n",
      "39987                          30  NaN    High  \n",
      "39988                          40  NaN     Low  \n",
      "39989                          40  NaN     Low  \n",
      "39990                          20  NaN    High  \n",
      "39991                          40  NaN    High  \n",
      "39992                          50  NaN    High  \n",
      "39993                          40  NaN    High  \n",
      "39994                          39  NaN    High  \n",
      "39995                          50  NaN     Low  \n",
      "39996                          40  NaN     Low  \n",
      "39997                          40  NaN    High  \n",
      "\n",
      "[38706 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-48e6b78c1184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mremainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'passthrough'\u001b[0m  \u001b[1;31m# This leaves the rest of my columns in place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mpreped_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreped_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    410\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m    411\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[1;32m--> 412\u001b[1;33m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 self._categorical_features, copy=True)\n\u001b[0;32m    630\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_legacy_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_categories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mXi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[1;32m---> 67\u001b[1;33m                              force_all_finite=needs_validation)\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Ok so we need to transform all catagorical data into objects / numbers of something cause yay!\n",
    "\n",
    "preped_df = df.drop(['sex'], axis=1)\n",
    "preped_df = preped_df.drop(['weighting'], axis=1)\n",
    "preped_df = df.drop(['sex'], axis=1)\n",
    "print(df.info())\n",
    "print(df)\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('oh_enc', OneHotEncoder(sparse=False), [2, 4, 5,6,8]),],  # the column numbers I want to apply this to\n",
    "    remainder='passthrough'  # This leaves the rest of my columns in place\n",
    ")\n",
    "preped_df = ct.fit_transform(preped_df)\n",
    "\n",
    "tree = pd.get_dummies(df)\n",
    "y = preped_df['at_risk']\n",
    "x = preped_df.drop(['at_risk'], axis=1).as_matrix()\n",
    "\n",
    "print(x)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  a. What is classification accuracy on training and test datasets?\n",
    "  \n",
    "  b. Which variable is used for the first split? What are the variables that are used for the second split?\n",
    "  \n",
    "  c. What are the 5 important variables in building the tree?\n",
    "  \n",
    "  d. Report if you see any evidence of model overfitting.\n",
    "  \n",
    "  \n",
    "2. Build another decision tree tuned with GridSearchCV. Examine the tree results.\n",
    "  \n",
    "  a. What is classification accuracy on training and test datasets?\n",
    "  \n",
    "  b. What are the parameters used? Explain your decision.\n",
    "  \n",
    "  c. What are the optimal parameters for this decision tree?\n",
    "  \n",
    "  d. Which variable is used for the first split? What are the variables that are used for the second split?\n",
    "  \n",
    "  e. What are the 5 important variables in building the tree?\n",
    "  \n",
    "  f. Report if you see any evidence of model overfitting.\n",
    "  \n",
    "  \n",
    "3. What is the significant difference do you see between these two decision tree models – default (Task 2.1) and using GridSearchCV (Task 2.2)? How do theycompare performance-wise? Explain why those changes may have happened.\n",
    "\n",
    "\n",
    "4. From the better model, can you identify which householders to target for providing loan? Can you provide some descriptive summary of those householders?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "## Predictive Modeling Using Regression (5.5 marks)\n",
    "1. Describe why you will have to do additional preparation for variables to be\n",
    "used in regression modelling. Apply transformation method(s) to the\n",
    "variable(s) that need it. List the variables that needed it.\n",
    "2. Build a regression model using the default regression method with all\n",
    "inputs. Once you have completed it, build another model and tune it usingGridSearchCV. Answer the followings:\n",
    "a. Report which variables are included in the regression model.\n",
    "b. Report the top-5 important variables (in the order) in the model.\n",
    "c. Report any sign of overfitting.\n",
    "d. What are the parameters used? Explain your decision. What are the\n",
    "optimal parameters? Which regression function is being used?\n",
    "e. What is classification accuracy on training and test datasets?\n",
    "3. Build another regression model using the subset of inputs selected either\n",
    "by RFE or the selection by model method. Answer the followings:\n",
    "a. Report which variables are included in the regression model.\n",
    "b. Report the top-5 important variables (in the order) in the model.\n",
    "c. Report any sign of overfitting.\n",
    "d. What is classification accuracy on training and test datasets?\n",
    "4. Using the comparison statistics, which of the regression models appears to\n",
    "be better? Is there any difference between the two models (i.e one with\n",
    "selected variables and another with all variables)? Explain why those\n",
    "changes may have happened.\n",
    "5. From the better model, can you identify which householders to target for\n",
    "providing loan? Can you provide some descriptive summary of those\n",
    "householders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "## Predictive Modeling Using Neural Networks (5.5 marks)\n",
    "1. Build a Neural Network model using the default setting. Answer the\n",
    "following:\n",
    "a. What are the parameters used? Explain your decision. What is the\n",
    "network architecture?\n",
    "b. How many iterations are needed to train this network?\n",
    "c. Do you see any sign of over-fitting?\n",
    "d. Did the training process converge and resulted in the best model?\n",
    "e. What is classification accuracy on training and test datasets?\n",
    "2. Refine this network by tuning it with GridSearchCV. Answer the\n",
    "following:\n",
    "a. What are the parameters used? Explain your decision. What is the\n",
    "network architecture?\n",
    "b. How many iterations are needed to train this network?\n",
    "c. Do you see any sign of over-fitting?\n",
    "d. Did the training process converge and resulted in the best model?\n",
    "e. What is classification accuracy on training and test datasets?\n",
    "3. Would feature selection help here? Build another Neural Network model\n",
    "with inputs selected from RFE with regression (use the best model\n",
    "generated in Task 3) and from the decision tree (use the best model\n",
    "from Task 2). Answer the following for the best neural network model:a. Did feature selection help here? Which method of feature selection\n",
    "produced the best result? Any change in the network architecture?\n",
    "What inputs are being used as the network input?\n",
    "b. What is classification accuracy on training and test datasets? Is there\n",
    "any improvement in the outcome?\n",
    "c. How many iterations are now needed to train this network?\n",
    "d. Do you see any sign of over-fitting?\n",
    "e. Did the training process converge and resulted in the best model?\n",
    "f. Finally, see whether the change in network architecture can further\n",
    "improve the performance, use GridSearchCV to tune the network.\n",
    "Report if there was any improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "## Comparing Predictive Models (4 marks)\n",
    "1. Use the comparison methods to compare the best decision tree model, the\n",
    "best regression model, and the best neural network model.\n",
    "a. Discuss the findings led by:\n",
    "(i) ROC Chart and Index;\n",
    "(ii) Accuracy Score;\n",
    "b. Which model would you use in deployment based on these findings?\n",
    "Discuss why?\n",
    "c. Do all the models agree on the householder’s characteristics? How do\n",
    "they vary?\n",
    "2. How the outcome of this study can be used by decision makers?\n",
    "3. Can you summarise the positives and negative aspects of each predictive\n",
    "modelling method based on this data analysis exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
